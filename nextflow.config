/*
Main configuration file:
Contains the following sections
	- Shell handling
	- External configuration files to include
	- Parameters
	- Profiles
	- Workflow introspection
	- Resource requirement function
*/

/*
################################################################################
Shell handling
-e: Exit immediately when command fails
-u: Exit if variable is unset
-o pipefail: prevents piping from causing a non-zero exit status
################################################################################
*/

process.shell = ['/bin/bash', '-euo', 'pipefail']

/*
################################################################################
Pipeline configuration files
################################################################################
*/

// includeConfig 'conf/genome.config'
includeConfig 'conf/base.config'

/*
################################################################################
Parameters
################################################################################
*/

params {

    // Help message
    help                        = false

    // Main parameters
    outdir                      = false

    // Set based on user partition
    partition                   = false
    max_memory                  = set_resources(params.partition, 'mem')
    max_cpus                    = set_resources(params.partition, 'cpu')
    max_time                    = set_resources(params.partition, 'time')
}
/*
################################################################################
Profiles
################################################################################
*/

profiles {
    standard{
        process.executor = 'local'
    }
    afw {
        process.executor = 'local'
    }
    phoenix {
        executor.name = 'slurm'
        executor.queueSize = params.partition == 'skylake' || 'skylakehm' ? 1000 : 2

        process.executor = 'slurm'
        process.queue = params.partition
        process.clusterOptions = "--nodes=1"
    }
    gadi {
        executor.name = 'pbspro'

        process.executor = 'pbspro'
        process.queue = params.partition
    }
    conda {
        conda.cacheDir = "/tmp/conda/"
        conda.createTimeout = '1 h'        
    }
    aws {
      process {
        withName: assembly_visualiser {
            process.conda = "/opt/conda/envs/3ddna"
            process.container "australianbiocommons/assembly"
        }
        withName: arima_map_filter_combine {
            process.conda "/opt/conda/envs/bwa2"
            process.container "australianbiocommons/assembly"
        }
        withName: arima_dedup_sort {
            process.conda "/opt/conda/envs/sort_dedup"
            process.container "australianbiocommons/assembly"
        }
        withName: "bcftools.*" {
            process.conda "/opt/conda/envs/bcftools"
            process.container "australianbiocommons/assembly"
        }
        withName: blast {
            process.conda "ncbi/blast"
            process.container "australianbiocommons/assembly"
        }
        withName: "busco.*" {
            process.conda "/opt/conda/envs/busco"
            process.container "australianbiocommons/assembly"
        }
        withName: "bwa.*" {
            process.conda "/opt/conda/envs/bwa2"
            process.container "australianbiocommons/assembly"
        }
        withName: kraken2 {
            process.conda "/opt/conda/envs/kraken2"
            process.container "australianbiocommons/assembly"
        }
        withName: fastqc { 
            process.conda "/opt/conda/envs/fastqc"
            process.container "australianbiocommons/assembly"
        }
        withName: salsa2 {
            process.conda "/opt/conda/envs/salsa2"
            process.container "australianbiocommons/assembly"
        }
        withName: matlock_bam2 { 
            process.conda "/opt/conda/envs/3ddna"
            process.container "australianbiocommons/assembly"
        }
        withName: kmc {
            process.conda "/opt/conda/envs/kmc"
            process.container "australianbiocommons/assembly"
        }
        withName: seqkit_fq2fa {
            process.conda "/opt/conda/envs/seqkit"
            process.container "australianbiocommons/assembly"
        } 
        withName: hifiadapterfilt {
            process.conda "/opt/conda/envs/hifiadapterfilt"
            process.container "australianbiocommons/assembly"
        }
        withName: genomescope {
            process.conda "/opt/conda/envs/genomescope2"
            process.container "australianbiocommons/assembly"
        }
        withName: hifiasm_hic { 
            process.conda "/opt/conda/envs/hifiasm"
            process.container "australianbiocommons/assembly"
        }
        withName: hifiasm {
            process.conda "/opt/conda/envs/hifiasm"
            process.container "australianbiocommons/assembly"
        }
      }
    }	  
}

/*
################################################################################
Workflow introspection
################################################################################
*/

report {
  enabled = true
  file = "${params.outdir}/reports/report.html"
}

timeline {
  enabled = true
  file = "${params.outdir}/reports/timeline.html"
}


dag {
  enabled = true
  file = "${params.outdir}/reports/DAG.svg"
}

trace {
  enabled = true
  fields = 'process,task_id,hash,name,attempt,status,exit,realtime,cpus,memory,%cpu,vmem,rss,submit,start,complete,duration,realtime,rchar,wchar'
  file = "${params.outdir}/reports/trace.txt"
}

/*
################################################################################
Check requested resources
################################################################################
*/

// It'll probably be good to have this build from the schema but will do for now
def set_resources(partition, resource) {
    def Map val = [:]
    switch(partition) {
        
        // phoenix
        case 'skylake':
            val.putAll( [ mem: 188.GB, cpu: 40, time: 72.h ] )
            break;
        case 'skylakehm':
            val.putAll( [ mem: 377.GB, cpu: 40, time: 72.h ] )
            break;
        case 'test':
            val.putAll( [ mem: 16.GB, cpu: 4, time: 2.h ] )
            break;

        // AFW
        case 'afw':
            val.putAll( [mem: 200.GB, cpu: 50, time: 168.h ] )
            break;
        
        // Gadi
        case 'normal':
            val.putAll( [ mem: 190.GB, cpu: 48, time: 48.h ] )
            break;

        // Standard
        default:
            val.putAll( [ mem: 4.GB, cpu: 4, time: 120.h ] )
            break;
    }

    // Return requested resource
    return val[resource]
}

def check_resources(val, max){
	// Check CPU value doesn't exceed the node limit 
	if( val instanceof Integer ) {
        try {
            return Math.min( val, max as int)
        }
        catch( all ) {
            println "WARNING: Max cpus '${max}' is not valid. Using default value: ${val}"
            return val
        }
    }
    // Check the memory value does exceed the memory limit
    if(val instanceof nextflow.util.MemoryUnit){
        try{
            def other = max as nextflow.util.MemoryUnit
            return val.compareTo(other) == 1 ? other : val
        }
        catch(all){
            println "WARNING: Max memory '${max}' is not valid. Using default value ${val}"
            return val
        }
    }
    // Check that the time duration does not exceed walltime limits
    if( val instanceof nextflow.util.Duration ) {
        try {
            def other = max as nextflow.util.Duration
            return val.compareTo(other) == 1 ? other : val
        }   
        catch( all ) {
            println "WARNING: Max time '${max}' is not valid. Using default value: ${val}"
            return val
        }  
    }
    
}
